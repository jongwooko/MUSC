{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cb92209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import data_loader.task_configs as task_configs\n",
    "from future.modules import ptl2classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a3be298-3197-45d2-ac07-996237aed466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: skip de trn: not such file\n",
      "./data/download/pawsx/dev-de.tsv 2000\n",
      "./data/download/pawsx/test-de.tsv 2000\n",
      "./data/download/pawsx/train-en.tsv 49401\n",
      "./data/download/pawsx/dev-en.tsv 2000\n",
      "./data/download/pawsx/test-en.tsv 2000\n",
      "[INFO]: skip es trn: not such file\n",
      "./data/download/pawsx/dev-es.tsv 2000\n",
      "./data/download/pawsx/test-es.tsv 2000\n",
      "[INFO]: skip fr trn: not such file\n",
      "./data/download/pawsx/dev-fr.tsv 2000\n",
      "./data/download/pawsx/test-fr.tsv 2000\n",
      "[INFO]: skip ja trn: not such file\n",
      "./data/download/pawsx/dev-ja.tsv 2000\n",
      "./data/download/pawsx/test-ja.tsv 2000\n",
      "[INFO]: skip ko trn: not such file\n",
      "./data/download/pawsx/dev-ko.tsv 2000\n",
      "./data/download/pawsx/test-ko.tsv 2000\n",
      "[INFO]: skip zh trn: not such file\n",
      "./data/download/pawsx/dev-zh.tsv 2000\n",
      "./data/download/pawsx/test-zh.tsv 2000\n",
      "2490 ./data/download/xnli/dev-ar.tsv\n",
      "5010 ./data/download/xnli/test-ar.tsv\n",
      "2490 ./data/download/xnli/dev-bg.tsv\n",
      "5010 ./data/download/xnli/test-bg.tsv\n",
      "2490 ./data/download/xnli/dev-de.tsv\n",
      "5010 ./data/download/xnli/test-de.tsv\n",
      "2490 ./data/download/xnli/dev-el.tsv\n",
      "5010 ./data/download/xnli/test-el.tsv\n",
      "2490 ./data/download/xnli/dev-en.tsv\n",
      "5010 ./data/download/xnli/test-en.tsv\n",
      "2490 ./data/download/xnli/dev-es.tsv\n",
      "5010 ./data/download/xnli/test-es.tsv\n",
      "2490 ./data/download/xnli/dev-fr.tsv\n",
      "5010 ./data/download/xnli/test-fr.tsv\n",
      "2490 ./data/download/xnli/dev-hi.tsv\n",
      "5010 ./data/download/xnli/test-hi.tsv\n",
      "2490 ./data/download/xnli/dev-ru.tsv\n",
      "5010 ./data/download/xnli/test-ru.tsv\n",
      "2490 ./data/download/xnli/dev-sw.tsv\n",
      "5010 ./data/download/xnli/test-sw.tsv\n",
      "2490 ./data/download/xnli/dev-th.tsv\n",
      "5010 ./data/download/xnli/test-th.tsv\n",
      "2490 ./data/download/xnli/dev-tr.tsv\n",
      "5010 ./data/download/xnli/test-tr.tsv\n",
      "2490 ./data/download/xnli/dev-ur.tsv\n",
      "5010 ./data/download/xnli/test-ur.tsv\n",
      "2490 ./data/download/xnli/dev-vi.tsv\n",
      "5010 ./data/download/xnli/test-vi.tsv\n",
      "2490 ./data/download/xnli/dev-zh.tsv\n",
      "5010 ./data/download/xnli/test-zh.tsv\n"
     ]
    }
   ],
   "source": [
    "for dataset in ['pawsx', 'xnli']: # marc, mldoc, pawsx, xnli\n",
    "    raw_dataset = task_configs.task2dataset[dataset]()\n",
    "    num_bucket = 40\n",
    "    \n",
    "    if dataset == 'marc':\n",
    "        shots = [1, 2, 4, 8]\n",
    "        langs = ['chinese', 'french', 'german', 'japanese', 'spanish']\n",
    "    elif dataset == 'pawsx':\n",
    "        shots = [1, 2, 4, 8]\n",
    "        langs = ['chinese', 'french', 'german', 'japanese', 'korean', 'spanish']\n",
    "    elif dataset == 'xnli':\n",
    "        shots = [1, 2, 4, 8]\n",
    "        langs = ['arabic', 'bulgarian', 'chinese', 'french', 'german', 'greek', 'hindi', 'russian', 'spanish', 'swahili', 'thai', 'turkish', 'urdu', 'vietnamese']\n",
    "    else:\n",
    "        raise ValueError\n",
    "    \n",
    "    for shot in shots:\n",
    "        for lang in langs:\n",
    "            lang_dataset = raw_dataset.get_language_data(language=lang)\n",
    "            val_egs = lang_dataset.val_egs\n",
    "            \n",
    "            label_list = []\n",
    "            for eg in val_egs:\n",
    "                label_list.append(eg.label)\n",
    "            label_list = np.array(label_list)\n",
    "            \n",
    "            selected_items = {}\n",
    "            for l in lang_dataset.label_list:\n",
    "                np.random.seed(42)\n",
    "                selected_items[l] = np.random.choice(np.where(label_list==l)[0], size=shot*num_bucket, replace=False)\n",
    "            \n",
    "            all_selected_idx = []\n",
    "            \n",
    "            for bucket in range(num_bucket):\n",
    "                pkl_data = {'eg_names': [], 'actual_egs': {}}\n",
    "                \n",
    "                for l in lang_dataset.label_list:\n",
    "                    selected_idx = selected_items[l][shot*bucket:shot*(bucket+1)].tolist()\n",
    "                    pkl_data['eg_names'] += selected_idx\n",
    "                    pkl_data['actual_egs'][l] = []\n",
    "                    for idx in selected_idx:\n",
    "                        pkl_data['actual_egs'][l].append(val_egs[idx])\n",
    "                    all_selected_idx += pkl_data['eg_names']\n",
    "                    pkl_data['eg_names'] = [str(i) for i in pkl_data['eg_names']]\n",
    "                \n",
    "                save_filename = './sampled_infos/sampled_data/{}/{}-shots/{}/{}-th/'.format(dataset, shot, lang, bucket)\n",
    "                os.makedirs(save_filename, exist_ok = True)\n",
    "                save_filename += 'sampled.pkl'\n",
    "                with open(save_filename, 'wb') as f:\n",
    "                    pickle.dump(pkl_data, f)\n",
    "                    \n",
    "            pkl_data = {}\n",
    "            for l in lang_dataset.label_list:\n",
    "                left_dev_idx = set(np.where(label_list==l)[0]) - set(all_selected_idx)\n",
    "                pkl_data[l] = []\n",
    "                for idx in left_dev_idx:\n",
    "                    pkl_data[l].append(val_egs[idx])\n",
    "            \n",
    "            save_filename = './sampled_infos/sampled_data/{}/{}-shots/{}/left,dev.pkl'.format(dataset, shot, lang)\n",
    "            with open(save_filename, 'wb') as f:\n",
    "                pickle.dump(pkl_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0879b4eb-3f8e-484a-8dff-defbb2824e57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = 'xnli'\n",
    "shot = 1\n",
    "lang = 'chinese'\n",
    "bucket = 15\n",
    "\n",
    "\n",
    "save_filename = './sampled_infos/sampled_data/{}/{}-shots/{}/{}-th/sampled.pkl'.format(dataset, shot, lang, bucket)\n",
    "save_filename = './sampled_infos/sampled_data/{}/{}-shots/{}/left,dev.pkl'.format(dataset, shot, lang, bucket)\n",
    "\n",
    "with open(save_filename, 'rb') as f:\n",
    "    pkl = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbc601b-0f8f-401c-84cb-03a757d90ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in ['panx', 'udpos']:\n",
    "    raw_dataset = task_configs.task2dataset[dataset]()\n",
    "    num_bucket = 40\n",
    "    \n",
    "    if dataset == 'panx':\n",
    "        shots = [1, 2, 4]\n",
    "        langs = ['af', 'ar', 'bg', 'bn', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'he', 'hi', 'hu', 'id', 'it', 'ja', 'jv', 'ka', 'kk', 'ko', 'ml', 'mr', 'ms', 'my', 'nl', 'pt', 'ru', 'sw', 'ta', 'te', 'th', 'tl', 'tr', 'ur', 'vi', 'yo', 'zh']\n",
    "    elif dataset == 'udpos':\n",
    "        shots = [1, 2, 4]\n",
    "        langs = ['af', 'ar', 'bg', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'he', 'hi', 'hu', 'id', 'it', 'ja', 'ko', 'mr', 'nl', 'pt', 'ru', 'ta', 'te', 'tr', 'ur', 'vi', 'zh']\n",
    "    else:\n",
    "        raise ValueError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsxlt",
   "language": "python",
   "name": "fsxlt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
