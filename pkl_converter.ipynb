{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a826c9b3-3107-4886-97e4-a0e407c26ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba48463-aaa1-4420-a816-42d89a16b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset : marc, panx, pawsx, udpos, xnli\n",
    "# marc, pawsx, xnli - {1,2,4,8} / panx, udpos - {1,2,4}\n",
    "# marc - ['chinese', 'french', 'german', 'japanese', 'spanish']\n",
    "# pawsx - ['chinese', 'french', 'german', 'japanese', 'korean', 'spanish']\n",
    "# xnli - ['arabic', 'bulgarian', 'chinese', 'french', 'german', 'greek', 'hindi', 'russian', 'spanish', 'swahili', 'thai', 'turkish', 'urdu', 'vietnamese']\n",
    "# panx - ['af', 'ar', 'bg', 'bn', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'he', 'hi', 'hu', 'id', 'it', 'ja', 'jv', 'ka', 'kk', 'ko', 'ml', 'mr', 'ms', 'my', 'nl', 'pt', 'ru', 'sw', 'ta', 'te', 'th', 'tl', 'tr', 'ur', 'vi', 'yo', 'zh']\n",
    "# udpos - ['af', 'ar', 'bg', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'he', 'hi', 'hu', 'id', 'it', 'ja', 'ko', 'mr', 'nl', 'pt', 'ru', 'ta', 'te', 'tr', 'ur', 'vi', 'zh']\n",
    "\n",
    "for dataset in ['marc', 'pawsx', 'xnli', 'panx', 'udpos']:\n",
    "    if dataset == 'marc':\n",
    "        shots = [1, 2, 4, 8]\n",
    "        langs = ['chinese', 'french', 'german', 'japanese', 'spanish']\n",
    "    elif dataset == 'pawsx':\n",
    "        shots = [1, 2, 4, 8]\n",
    "        langs = ['chinese', 'french', 'german', 'japanese', 'korean', 'spanish']\n",
    "    elif dataset == 'xnli':\n",
    "        shots = [1, 2, 4, 8]\n",
    "        langs = ['arabic', 'bulgarian', 'chinese', 'french', 'german', 'greek', 'hindi', 'russian', 'spanish', 'swahili', 'thai', 'turkish', 'urdu', 'vietnamese']\n",
    "    elif dataset == 'panx':\n",
    "        shots = [1, 2, 4]\n",
    "        langs = ['af', 'ar', 'bg', 'bn', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'he', 'hi', 'hu', 'id', 'it', 'ja', 'jv', 'ka', 'kk', 'ko', 'ml', 'mr', 'ms', 'my', 'nl', 'pt', 'ru', 'sw', 'ta', 'te', 'th', 'tl', 'tr', 'ur', 'vi', 'yo', 'zh']\n",
    "        continue\n",
    "    elif dataset == 'udpos':\n",
    "        shots = [1, 2, 4]\n",
    "        langs = ['af', 'ar', 'bg', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'he', 'hi', 'hu', 'id', 'it', 'ja', 'ko', 'mr', 'nl', 'pt', 'ru', 'ta', 'te', 'tr', 'ur', 'vi', 'zh']\n",
    "        continue\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    for shot in shots:\n",
    "        for lang in langs:\n",
    "            for group_index in range(40):\n",
    "                json_filename = './buckets/{}/{}-shots/{}/{}-th/sampled.json'.format(dataset, shot, lang, group_index)\n",
    "                with open(json_filename, \"r\") as f:\n",
    "                    json_file = json.load(f)\n",
    "\n",
    "                eg_names_lst = [v[0]['uid'].split('-')[1] for k, v in json_file.items()]\n",
    "                new_json_file = {'eg_names': eg_names_lst,\n",
    "                                 'actual_egs': json_file}\n",
    "\n",
    "                pkl_filename = './sampled_infos/sampled_data/{}/{}-shots/{}/{}-th/'.format(dataset, shot, lang, group_index)\n",
    "                os.makedirs(pkl_filename, exist_ok = True)\n",
    "                pkl_filename = pkl_filename + 'sampled.pkl'\n",
    "\n",
    "                with open(pkl_filename, 'wb') as f:\n",
    "                    pickle.dump(new_json_file, f)\n",
    "\n",
    "                # with open(pkl_filename, \"rb\") as f:\n",
    "                #     pkl_file = pickle.load(f)\n",
    "                # print (pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898d62f0-2eda-4e98-a8b4-9f6c4b395a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lang == 'chinese':\n",
    "    for k, v in json_file.items():\n",
    "        text_a = json_file[k][0]['text_a']\n",
    "        text_b = json_file[k][0]['text_b']\n",
    "        \n",
    "        json_file[k][0]['text_a'] = ''.join(r'\\u{:04x}'.format(ord(char)) for char in text_a)\n",
    "        json_file[k][0]['text_b'] = ''.join(r'\\u{:04x}'.format(ord(char)) for char in text_b.split(' . ')[0]) + ' . ' + text_b.split(' . ')[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
